{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "acd08801",
   "metadata": {},
   "source": [
    "# Synful Training Pipeline Visualization\n",
    "\n",
    "This notebook provides a comprehensive visualization of the Synful training data pipeline. Each cell demonstrates a different stage of data processing, from raw input data to training-ready batches.\n",
    "\n",
    "## Pipeline Overview\n",
    "\n",
    "1. **Data Loading**: Load synapse locations from TSV files or MongoDB\n",
    "2. **Volume Access**: Load electron microscopy volumes from Zarr files  \n",
    "3. **Spatial Extraction**: Extract training cubes around synapse locations\n",
    "4. **Mask Generation**: Create binary masks at synapse locations\n",
    "5. **Direction Vectors**: Generate pre‚Üípost direction vectors for multitask learning\n",
    "6. **Data Augmentation**: Apply 3D geometric and intensity augmentations\n",
    "7. **Final Training Data**: Visualize the complete training batch\n",
    "\n",
    "Let's explore each step in detail!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "239dcbe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Required Libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# 3D visualization\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "# Set plotting style\n",
    "plt.style.use('default')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "# Configure matplotlib for better output\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (10, 8)\n",
    "plt.rcParams['font.size'] = 12\n",
    "\n",
    "print(\"‚úÖ Successfully imported all required libraries\")\n",
    "print(\"üìä Ready for Synful pipeline visualization\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ff1a02f",
   "metadata": {},
   "source": [
    "## Step 1: Load and Parse TSV Synapse Data\n",
    "\n",
    "The first step is loading synapse location data. Synful supports multiple formats:\n",
    "- **TSV files**: Simple tab-separated files with pre/post coordinates\n",
    "- **MongoDB**: Production database with spatial indexing\n",
    "- **Synthetic**: Generated data for testing\n",
    "\n",
    "TSV format expected:\n",
    "```\n",
    "pre_x    pre_y    pre_z    post_x    post_y    post_z\n",
    "1000.0   2000.0   500.0    1100.0    2100.0   510.0\n",
    "1500.0   2500.0   600.0    1600.0    2600.0   610.0\n",
    "...\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d91216e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create sample TSV data for demonstration\n",
    "def create_sample_tsv_data(n_synapses=100, volume_size=(10000, 10000, 1000)):\n",
    "    \"\"\"Create sample synapse data for visualization\"\"\"\n",
    "    np.random.seed(42)  # For reproducible results\n",
    "    \n",
    "    # Generate random pre-synapse locations\n",
    "    pre_x = np.random.uniform(1000, volume_size[0]-1000, n_synapses)\n",
    "    pre_y = np.random.uniform(1000, volume_size[1]-1000, n_synapses)\n",
    "    pre_z = np.random.uniform(100, volume_size[2]-100, n_synapses)\n",
    "    \n",
    "    # Generate post-synapse locations nearby (synapses are typically close)\n",
    "    post_x = pre_x + np.random.normal(0, 50, n_synapses)  # 50nm std\n",
    "    post_y = pre_y + np.random.normal(0, 50, n_synapses)\n",
    "    post_z = pre_z + np.random.normal(0, 20, n_synapses)  # smaller in z\n",
    "    \n",
    "    # Create DataFrame\n",
    "    synapse_data = pd.DataFrame({\n",
    "        'pre_x': pre_x,\n",
    "        'pre_y': pre_y, \n",
    "        'pre_z': pre_z,\n",
    "        'post_x': post_x,\n",
    "        'post_y': post_y,\n",
    "        'post_z': post_z\n",
    "    })\n",
    "    \n",
    "    return synapse_data\n",
    "\n",
    "# Load or create synapse data\n",
    "synapse_df = create_sample_tsv_data(n_synapses=200)\n",
    "\n",
    "print(f\"üìä Loaded synapse data: {len(synapse_df)} synapses\")\n",
    "print(f\"üìê Data shape: {synapse_df.shape}\")\n",
    "print(\"\\\\nüîç First 5 synapses:\")\n",
    "print(synapse_df.head())\n",
    "\n",
    "print(\"\\\\nüìà Data statistics:\")\n",
    "print(synapse_df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eb83089",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize raw synapse data distribution\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "\n",
    "# Pre-synapse locations\n",
    "axes[0,0].scatter(synapse_df['pre_x'], synapse_df['pre_y'], \n",
    "                  c=synapse_df['pre_z'], cmap='viridis', alpha=0.7)\n",
    "axes[0,0].set_xlabel('X (nm)')\n",
    "axes[0,0].set_ylabel('Y (nm)')\n",
    "axes[0,0].set_title('Pre-synapse Locations (XY, colored by Z)')\n",
    "axes[0,0].grid(True, alpha=0.3)\n",
    "\n",
    "# Post-synapse locations  \n",
    "axes[0,1].scatter(synapse_df['post_x'], synapse_df['post_y'],\n",
    "                  c=synapse_df['post_z'], cmap='viridis', alpha=0.7)\n",
    "axes[0,1].set_xlabel('X (nm)')\n",
    "axes[0,1].set_ylabel('Y (nm)')\n",
    "axes[0,1].set_title('Post-synapse Locations (XY, colored by Z)')\n",
    "axes[0,1].grid(True, alpha=0.3)\n",
    "\n",
    "# Z-distribution\n",
    "axes[1,0].hist([synapse_df['pre_z'], synapse_df['post_z']], \n",
    "               bins=20, alpha=0.7, label=['Pre', 'Post'])\n",
    "axes[1,0].set_xlabel('Z coordinate (nm)')\n",
    "axes[1,0].set_ylabel('Count')\n",
    "axes[1,0].set_title('Z-coordinate Distribution')\n",
    "axes[1,0].legend()\n",
    "axes[1,0].grid(True, alpha=0.3)\n",
    "\n",
    "# Coordinate ranges\n",
    "coord_ranges = pd.DataFrame({\n",
    "    'Min': [synapse_df[col].min() for col in synapse_df.columns],\n",
    "    'Max': [synapse_df[col].max() for col in synapse_df.columns],\n",
    "    'Range': [synapse_df[col].max() - synapse_df[col].min() for col in synapse_df.columns]\n",
    "}, index=synapse_df.columns)\n",
    "\n",
    "axes[1,1].table(cellText=coord_ranges.round(1).values,\n",
    "                rowLabels=coord_ranges.index,\n",
    "                colLabels=coord_ranges.columns,\n",
    "                cellLoc='center',\n",
    "                loc='center')\n",
    "axes[1,1].set_title('Coordinate Ranges (nm)')\n",
    "axes[1,1].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"‚úÖ Synapse data visualization complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56ea3ec5",
   "metadata": {},
   "source": [
    "## Step 2: Extract Pre and Post-Synapse Coordinates\n",
    "\n",
    "Now we'll separate the coordinates and visualize the 3D spatial distribution of synapses. This helps us understand:\n",
    "- Spatial density of synapses\n",
    "- Clustering patterns\n",
    "- Volume coverage\n",
    "- Pre/post relationship geometry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a410916f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract coordinate arrays (convert to Synful internal format: z,y,x)\n",
    "pre_coords = synapse_df[['pre_z', 'pre_y', 'pre_x']].values  # z,y,x order\n",
    "post_coords = synapse_df[['post_z', 'post_y', 'post_x']].values\n",
    "\n",
    "print(f\"üìê Pre-synapse coordinates shape: {pre_coords.shape}\")\n",
    "print(f\"üìê Post-synapse coordinates shape: {post_coords.shape}\")\n",
    "\n",
    "# 3D visualization of synapse locations\n",
    "fig = plt.figure(figsize=(16, 6))\n",
    "\n",
    "# Plot 1: Pre-synapses\n",
    "ax1 = fig.add_subplot(131, projection='3d')\n",
    "scatter1 = ax1.scatter(pre_coords[:, 2], pre_coords[:, 1], pre_coords[:, 0], \n",
    "                       c='red', alpha=0.6, s=20, label='Pre-synapse')\n",
    "ax1.set_xlabel('X (nm)')\n",
    "ax1.set_ylabel('Y (nm)')\n",
    "ax1.set_zlabel('Z (nm)')\n",
    "ax1.set_title('Pre-synapse Locations')\n",
    "\n",
    "# Plot 2: Post-synapses  \n",
    "ax2 = fig.add_subplot(132, projection='3d')\n",
    "scatter2 = ax2.scatter(post_coords[:, 2], post_coords[:, 1], post_coords[:, 0],\n",
    "                       c='blue', alpha=0.6, s=20, label='Post-synapse')\n",
    "ax2.set_xlabel('X (nm)')\n",
    "ax2.set_ylabel('Y (nm)')\n",
    "ax2.set_zlabel('Z (nm)')\n",
    "ax2.set_title('Post-synapse Locations')\n",
    "\n",
    "# Plot 3: Both together with connections\n",
    "ax3 = fig.add_subplot(133, projection='3d')\n",
    "ax3.scatter(pre_coords[:, 2], pre_coords[:, 1], pre_coords[:, 0],\n",
    "            c='red', alpha=0.6, s=20, label='Pre')\n",
    "ax3.scatter(post_coords[:, 2], post_coords[:, 1], post_coords[:, 0],\n",
    "            c='blue', alpha=0.6, s=20, label='Post')\n",
    "\n",
    "# Draw connections for first 50 synapses (to avoid clutter)\n",
    "for i in range(min(50, len(pre_coords))):\n",
    "    ax3.plot([pre_coords[i, 2], post_coords[i, 2]],\n",
    "             [pre_coords[i, 1], post_coords[i, 1]],\n",
    "             [pre_coords[i, 0], post_coords[i, 0]],\n",
    "             'k-', alpha=0.3, linewidth=0.5)\n",
    "\n",
    "ax3.set_xlabel('X (nm)')\n",
    "ax3.set_ylabel('Y (nm)')\n",
    "ax3.set_zlabel('Z (nm)')\n",
    "ax3.set_title('Pre-Post Connections')\n",
    "ax3.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"‚úÖ Extracted coordinates for {len(pre_coords)} synapses\")\n",
    "print(f\"üìä Coordinate format: Z,Y,X (Synful internal format)\")\n",
    "print(f\"üîó Visualized spatial distribution and connections\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc1823a2",
   "metadata": {},
   "source": [
    "## Step 3: Calculate Synapse Vector Features\n",
    "\n",
    "This step computes important geometric features used in training:\n",
    "- **Direction vectors**: Pre ‚Üí Post displacement  \n",
    "- **Distances**: Euclidean distance between partners\n",
    "- **Orientations**: 3D direction angles\n",
    "- **Spatial statistics**: For understanding synapse geometry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "748d724a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate direction vectors (pre -> post)\n",
    "direction_vectors = post_coords - pre_coords\n",
    "\n",
    "# Calculate distances\n",
    "distances = np.linalg.norm(direction_vectors, axis=1)\n",
    "\n",
    "# Calculate angles (elevation and azimuth)\n",
    "# Elevation: angle from XY plane\n",
    "elevation_angles = np.arctan2(direction_vectors[:, 0], \n",
    "                             np.sqrt(direction_vectors[:, 1]**2 + direction_vectors[:, 2]**2))\n",
    "# Azimuth: angle in XY plane\n",
    "azimuth_angles = np.arctan2(direction_vectors[:, 1], direction_vectors[:, 2])\n",
    "\n",
    "# Convert to degrees\n",
    "elevation_deg = np.degrees(elevation_angles)\n",
    "azimuth_deg = np.degrees(azimuth_angles)\n",
    "\n",
    "print(f\"üìä Vector Features Summary:\")\n",
    "print(f\"   Distance range: {distances.min():.1f} - {distances.max():.1f} nm\")\n",
    "print(f\"   Mean distance: {distances.mean():.1f} ¬± {distances.std():.1f} nm\")\n",
    "print(f\"   Direction vector shape: {direction_vectors.shape}\")\n",
    "\n",
    "# Visualize vector features\n",
    "fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "\n",
    "# Distance distribution\n",
    "axes[0,0].hist(distances, bins=30, alpha=0.7, color='skyblue', edgecolor='black')\n",
    "axes[0,0].set_xlabel('Distance (nm)')\n",
    "axes[0,0].set_ylabel('Count')\n",
    "axes[0,0].set_title('Synapse Partner Distances')\n",
    "axes[0,0].grid(True, alpha=0.3)\n",
    "\n",
    "# Direction vector components\n",
    "for i, axis_name in enumerate(['Z', 'Y', 'X']):\n",
    "    axes[0,1].hist(direction_vectors[:, i], bins=30, alpha=0.5, \n",
    "                   label=f'{axis_name} component')\n",
    "axes[0,1].set_xlabel('Vector component (nm)')\n",
    "axes[0,1].set_ylabel('Count')\n",
    "axes[0,1].set_title('Direction Vector Components')\n",
    "axes[0,1].legend()\n",
    "axes[0,1].grid(True, alpha=0.3)\n",
    "\n",
    "# Angle distributions\n",
    "axes[0,2].hist(elevation_deg, bins=30, alpha=0.7, color='orange')\n",
    "axes[0,2].set_xlabel('Elevation angle (degrees)')\n",
    "axes[0,2].set_ylabel('Count')\n",
    "axes[0,2].set_title('Elevation Angles (from XY plane)')\n",
    "axes[0,2].grid(True, alpha=0.3)\n",
    "\n",
    "# Distance vs vector magnitude\n",
    "axes[1,0].scatter(distances, np.linalg.norm(direction_vectors, axis=1), alpha=0.6)\n",
    "axes[1,0].plot([0, distances.max()], [0, distances.max()], 'r--', alpha=0.5)\n",
    "axes[1,0].set_xlabel('Calculated Distance (nm)')\n",
    "axes[1,0].set_ylabel('Vector Magnitude (nm)')\n",
    "axes[1,0].set_title('Distance Validation')\n",
    "axes[1,0].grid(True, alpha=0.3)\n",
    "\n",
    "# Azimuth distribution (polar plot)\n",
    "ax_polar = plt.subplot(2, 3, 5, projection='polar')\n",
    "ax_polar.hist(azimuth_angles, bins=20, alpha=0.7)\n",
    "ax_polar.set_title('Azimuth Angle Distribution')\n",
    "\n",
    "# 3D direction vectors (quiver plot sample)\n",
    "ax_3d = fig.add_subplot(236, projection='3d')\n",
    "# Show subset to avoid clutter\n",
    "subset_idx = np.random.choice(len(pre_coords), size=20, replace=False)\n",
    "ax_3d.quiver(pre_coords[subset_idx, 2], pre_coords[subset_idx, 1], pre_coords[subset_idx, 0],\n",
    "             direction_vectors[subset_idx, 2], direction_vectors[subset_idx, 1], direction_vectors[subset_idx, 0],\n",
    "             length=0.5, normalize=True, alpha=0.7)\n",
    "ax_3d.set_xlabel('X (nm)')\n",
    "ax_3d.set_ylabel('Y (nm)')\n",
    "ax_3d.set_zlabel('Z (nm)')\n",
    "ax_3d.set_title('Direction Vectors (sample)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"‚úÖ Vector features calculated and visualized\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ca5c541",
   "metadata": {},
   "source": [
    "## Step 4: Simulate Volume Data and Training Cube Extraction\n",
    "\n",
    "Now we simulate loading from a large Zarr volume and extracting training cubes around synapse locations. This demonstrates:\n",
    "- Volume data structure and properties\n",
    "- Spatial cube extraction\n",
    "- Training data organization\n",
    "- Memory-efficient sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa9e1601",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulate volume data and cube extraction\n",
    "def simulate_em_volume_cube(center_coords, cube_size=(42, 430, 430), voxel_size=(40, 4, 4)):\n",
    "    \"\"\"Simulate extracting a training cube from EM volume\"\"\"\n",
    "    \n",
    "    # Convert physical coordinates to voxel coordinates\n",
    "    voxel_coords = center_coords / np.array(voxel_size)\n",
    "    voxel_coords = voxel_coords.astype(int)\n",
    "    \n",
    "    # Create synthetic EM-like data\n",
    "    cube = np.random.randn(*cube_size).astype(np.float32)\n",
    "    \n",
    "    # Add some structure to make it look more EM-like\n",
    "    # Add some membrane-like features\n",
    "    for _ in range(5):\n",
    "        membrane_z = np.random.randint(5, cube_size[0]-5)\n",
    "        membrane_thickness = np.random.randint(1, 3)\n",
    "        cube[membrane_z:membrane_z+membrane_thickness, :, :] += np.random.uniform(1, 2)\n",
    "    \n",
    "    # Add noise and normalize\n",
    "    cube += np.random.normal(0, 0.1, cube.shape)\n",
    "    cube = (cube - cube.mean()) / cube.std()\n",
    "    \n",
    "    return cube, voxel_coords\n",
    "\n",
    "# Configuration matching training parameters\n",
    "cube_size = (42, 430, 430)  # z, y, x in voxels\n",
    "voxel_size = (40, 4, 4)     # z, y, x in nm\n",
    "physical_cube_size = np.array(cube_size) * np.array(voxel_size)\n",
    "\n",
    "print(f\"üìê Training cube configuration:\")\n",
    "print(f\"   Cube size (voxels): {cube_size}\")\n",
    "print(f\"   Voxel size (nm): {voxel_size}\")\n",
    "print(f\"   Physical size (nm): {physical_cube_size}\")\n",
    "print(f\"   Total volume: {np.prod(cube_size):,} voxels\")\n",
    "\n",
    "# Extract training cubes for first few synapses\n",
    "n_samples = 3\n",
    "sample_cubes = []\n",
    "sample_coords = []\n",
    "\n",
    "for i in range(n_samples):\n",
    "    # Use middle point between pre and post as cube center\n",
    "    center_coord = (pre_coords[i] + post_coords[i]) / 2\n",
    "    \n",
    "    cube, voxel_coord = simulate_em_volume_cube(center_coord, cube_size, voxel_size)\n",
    "    sample_cubes.append(cube)\n",
    "    sample_coords.append(voxel_coord)\n",
    "    \n",
    "    print(f\"Synapse {i+1}: Center at {center_coord} nm -> {voxel_coord} voxels\")\n",
    "\n",
    "# Visualize extracted cubes\n",
    "fig, axes = plt.subplots(n_samples, 3, figsize=(15, n_samples*4))\n",
    "if n_samples == 1:\n",
    "    axes = axes.reshape(1, -1)\n",
    "\n",
    "for i in range(n_samples):\n",
    "    cube = sample_cubes[i]\n",
    "    \n",
    "    # Show different slices through the cube\n",
    "    mid_z = cube.shape[0] // 2\n",
    "    mid_y = cube.shape[1] // 2\n",
    "    mid_x = cube.shape[2] // 2\n",
    "    \n",
    "    # XY slice (middle Z)\n",
    "    im1 = axes[i, 0].imshow(cube[mid_z, :, :], cmap='gray', aspect='auto')\n",
    "    axes[i, 0].set_title(f'Synapse {i+1}: XY slice (Z={mid_z})')\n",
    "    axes[i, 0].set_xlabel('X (voxels)')\n",
    "    axes[i, 0].set_ylabel('Y (voxels)')\n",
    "    \n",
    "    # XZ slice (middle Y)\n",
    "    im2 = axes[i, 1].imshow(cube[:, mid_y, :], cmap='gray', aspect='auto')\n",
    "    axes[i, 1].set_title(f'XZ slice (Y={mid_y})')\n",
    "    axes[i, 1].set_xlabel('X (voxels)')\n",
    "    axes[i, 1].set_ylabel('Z (voxels)')\n",
    "    \n",
    "    # YZ slice (middle X)\n",
    "    im3 = axes[i, 2].imshow(cube[:, :, mid_x], cmap='gray', aspect='auto')\n",
    "    axes[i, 2].set_title(f'YZ slice (X={mid_x})')\n",
    "    axes[i, 2].set_xlabel('Y (voxels)')\n",
    "    axes[i, 2].set_ylabel('Z (voxels)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"‚úÖ Extracted {n_samples} training cubes\")\n",
    "print(f\"üìä Cube statistics:\")\n",
    "for i, cube in enumerate(sample_cubes):\n",
    "    print(f\"   Cube {i+1}: {cube.shape}, range: {cube.min():.3f} to {cube.max():.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2669e705",
   "metadata": {},
   "source": [
    "## Step 5: Generate Training Masks and Direction Vectors\n",
    "\n",
    "This is the core of Synful training data preparation:\n",
    "- **Binary masks**: Mark synapse locations in the volume\n",
    "- **Direction vectors**: Encode pre‚Üípost direction at each voxel\n",
    "- **Multitask outputs**: Both detection (mask) and direction prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dcfad42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate training masks and direction vectors\n",
    "def create_synapse_mask_and_vectors(cube_shape, synapse_coords, direction_vector, \n",
    "                                   blob_radius=10, d_blob_radius=100, voxel_size=(40, 4, 4)):\n",
    "    \"\"\"Create training mask and direction vectors for a cube\"\"\"\n",
    "    \n",
    "    # Initialize outputs\n",
    "    mask = np.zeros(cube_shape, dtype=np.float32)\n",
    "    direction_map = np.zeros((3,) + cube_shape, dtype=np.float32)  # 3D vectors\n",
    "    \n",
    "    # Convert synapse coordinates to cube coordinates\n",
    "    cube_center = np.array(cube_shape) // 2\n",
    "    \n",
    "    # For this demo, place synapse at cube center\n",
    "    # In real training, this would be calculated from actual coordinates\n",
    "    synapse_voxel = cube_center.astype(int)\n",
    "    \n",
    "    # Create spherical mask around synapse location\n",
    "    z_indices, y_indices, x_indices = np.mgrid[0:cube_shape[0], 0:cube_shape[1], 0:cube_shape[2]]\n",
    "    \n",
    "    # Calculate distance from synapse center\n",
    "    dz = (z_indices - synapse_voxel[0]) * voxel_size[0]\n",
    "    dy = (y_indices - synapse_voxel[1]) * voxel_size[1] \n",
    "    dx = (x_indices - synapse_voxel[2]) * voxel_size[2]\n",
    "    \n",
    "    distance = np.sqrt(dz**2 + dy**2 + dx**2)\n",
    "    \n",
    "    # Create binary mask within blob_radius\n",
    "    mask[distance <= blob_radius] = 1.0\n",
    "    \n",
    "    # Create direction vectors within d_blob_radius\n",
    "    direction_mask = distance <= d_blob_radius\n",
    "    \n",
    "    # Normalize direction vector\n",
    "    norm_direction = direction_vector / (np.linalg.norm(direction_vector) + 1e-8)\n",
    "    \n",
    "    # Set direction vectors where mask is active\n",
    "    for i in range(3):\n",
    "        direction_map[i][direction_mask] = norm_direction[i]\n",
    "    \n",
    "    return mask, direction_map\n",
    "\n",
    "# Generate masks and direction vectors for sample cubes\n",
    "sample_masks = []\n",
    "sample_directions = []\n",
    "\n",
    "for i in range(n_samples):\n",
    "    # Get synapse direction vector\n",
    "    direction = direction_vectors[i]\n",
    "    \n",
    "    # Create mask and direction map\n",
    "    mask, direction_map = create_synapse_mask_and_vectors(\n",
    "        cube_size, sample_coords[i], direction\n",
    "    )\n",
    "    \n",
    "    sample_masks.append(mask)\n",
    "    sample_directions.append(direction_map)\n",
    "    \n",
    "    print(f\"Synapse {i+1}: Mask has {mask.sum():.0f} positive voxels, \"\n",
    "          f\"direction magnitude: {np.linalg.norm(direction):.2f}\")\n",
    "\n",
    "# Visualize masks and direction vectors\n",
    "fig, axes = plt.subplots(n_samples, 4, figsize=(20, n_samples*4))\n",
    "if n_samples == 1:\n",
    "    axes = axes.reshape(1, -1)\n",
    "\n",
    "for i in range(n_samples):\n",
    "    cube = sample_cubes[i]\n",
    "    mask = sample_masks[i]\n",
    "    direction_map = sample_directions[i]\n",
    "    \n",
    "    mid_z = cube.shape[0] // 2\n",
    "    \n",
    "    # Original volume slice\n",
    "    axes[i, 0].imshow(cube[mid_z, :, :], cmap='gray', alpha=0.8)\n",
    "    axes[i, 0].set_title(f'Synapse {i+1}: Raw Volume')\n",
    "    axes[i, 0].set_xlabel('X (voxels)')\n",
    "    axes[i, 0].set_ylabel('Y (voxels)')\n",
    "    \n",
    "    # Mask overlay\n",
    "    axes[i, 1].imshow(cube[mid_z, :, :], cmap='gray', alpha=0.7)\n",
    "    mask_slice = mask[mid_z, :, :]\n",
    "    axes[i, 1].contour(mask_slice, levels=[0.5], colors='red', linewidths=2)\n",
    "    axes[i, 1].set_title('Synapse Mask (red contour)')\n",
    "    axes[i, 1].set_xlabel('X (voxels)')\n",
    "    axes[i, 1].set_ylabel('Y (voxels)')\n",
    "    \n",
    "    # Direction vector magnitude\n",
    "    direction_magnitude = np.linalg.norm(direction_map, axis=0)\n",
    "    im3 = axes[i, 2].imshow(direction_magnitude[mid_z, :, :], cmap='viridis')\n",
    "    axes[i, 2].set_title('Direction Vector Magnitude')\n",
    "    axes[i, 2].set_xlabel('X (voxels)')\n",
    "    axes[i, 2].set_ylabel('Y (voxels)')\n",
    "    plt.colorbar(im3, ax=axes[i, 2], fraction=0.046)\n",
    "    \n",
    "    # Direction vector field (subsample for visibility)\n",
    "    step = 20\n",
    "    y_sub = slice(None, None, step)\n",
    "    x_sub = slice(None, None, step)\n",
    "    \n",
    "    Y, X = np.meshgrid(np.arange(0, cube_size[1], step), \n",
    "                       np.arange(0, cube_size[2], step), indexing='ij')\n",
    "    \n",
    "    dy_field = direction_map[1, mid_z, y_sub, x_sub]\n",
    "    dx_field = direction_map[2, mid_z, y_sub, x_sub]\n",
    "    \n",
    "    axes[i, 3].imshow(cube[mid_z, :, :], cmap='gray', alpha=0.5)\n",
    "    axes[i, 3].quiver(X, Y, dx_field, dy_field, \n",
    "                     scale=10, scale_units='xy', alpha=0.8, color='red')\n",
    "    axes[i, 3].set_title('Direction Vector Field')\n",
    "    axes[i, 3].set_xlabel('X (voxels)')\n",
    "    axes[i, 3].set_ylabel('Y (voxels)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Statistics\n",
    "print(\"\\\\nüìä Training Target Statistics:\")\n",
    "for i in range(n_samples):\n",
    "    mask = sample_masks[i]\n",
    "    direction_map = sample_directions[i]\n",
    "    \n",
    "    mask_ratio = mask.sum() / mask.size * 100\n",
    "    direction_magnitude = np.linalg.norm(direction_map, axis=0)\n",
    "    direction_active = (direction_magnitude > 0).sum()\n",
    "    \n",
    "    print(f\"   Synapse {i+1}:\")\n",
    "    print(f\"     Mask coverage: {mask_ratio:.3f}% of volume\")\n",
    "    print(f\"     Direction active voxels: {direction_active:,}\")\n",
    "    print(f\"     Mean direction magnitude: {direction_magnitude.mean():.3f}\")\n",
    "\n",
    "print(\"\\\\n‚úÖ Training masks and direction vectors generated\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01b1d35d",
   "metadata": {},
   "source": [
    "## Step 6: Apply Data Augmentations\n",
    "\n",
    "Data augmentation is crucial for training robust models. Synful uses sophisticated 3D augmentations:\n",
    "- **Geometric**: Rotations, flips, elastic deformation\n",
    "- **Intensity**: Scaling, shifting, gamma correction  \n",
    "- **Noise**: Gaussian noise, salt-and-pepper artifacts\n",
    "\n",
    "Let's see how these affect our training data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9cf8ca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulate the augmentation pipeline\n",
    "def apply_intensity_augmentation(volume, scale_range=(0.8, 1.2), shift_range=(-0.2, 0.2)):\n",
    "    \"\"\"Apply intensity augmentations\"\"\"\n",
    "    augmented = volume.copy()\n",
    "    \n",
    "    # Random intensity scaling\n",
    "    scale = np.random.uniform(*scale_range)\n",
    "    augmented = augmented * scale\n",
    "    \n",
    "    # Random intensity shift\n",
    "    shift = np.random.uniform(*shift_range)\n",
    "    augmented = augmented + shift\n",
    "    \n",
    "    # Random gamma correction (30% chance)\n",
    "    if np.random.random() < 0.3:\n",
    "        gamma = np.random.uniform(0.8, 1.2)\n",
    "        augmented = np.sign(augmented) * np.power(np.abs(augmented), gamma)\n",
    "    \n",
    "    return augmented\n",
    "\n",
    "def apply_noise_augmentation(volume, noise_std=0.1):\n",
    "    \"\"\"Apply noise augmentations\"\"\"\n",
    "    augmented = volume.copy()\n",
    "    \n",
    "    # Gaussian noise\n",
    "    noise = np.random.normal(0, noise_std, volume.shape)\n",
    "    augmented = augmented + noise\n",
    "    \n",
    "    # Salt and pepper noise (10% chance)\n",
    "    if np.random.random() < 0.1:\n",
    "        mask = np.random.random(volume.shape) < 0.01\n",
    "        augmented[mask] = np.random.uniform(-1, 1, mask.sum())\n",
    "    \n",
    "    return augmented\n",
    "\n",
    "def apply_geometric_augmentation(volume, mask, direction_map):\n",
    "    \"\"\"Apply geometric augmentations (simplified for demo)\"\"\"\n",
    "    # For demonstration, we'll just flip along one axis\n",
    "    if np.random.random() < 0.5:\n",
    "        # Flip Y axis\n",
    "        volume = np.flip(volume, axis=1)\n",
    "        mask = np.flip(mask, axis=1)\n",
    "        direction_map = np.flip(direction_map, axis=2)  # axis 2 corresponds to Y in direction map\n",
    "        direction_map[1] *= -1  # Flip Y component of direction vectors\n",
    "    \n",
    "    return volume, mask, direction_map\n",
    "\n",
    "# Apply augmentations to first sample\n",
    "original_cube = sample_cubes[0].copy()\n",
    "original_mask = sample_masks[0].copy()\n",
    "original_direction = sample_directions[0].copy()\n",
    "\n",
    "# Create multiple augmented versions\n",
    "n_augmentations = 4\n",
    "augmented_data = []\n",
    "\n",
    "np.random.seed(123)  # For reproducible demo\n",
    "for aug_idx in range(n_augmentations):\n",
    "    # Start with original\n",
    "    aug_cube = original_cube.copy()\n",
    "    aug_mask = original_mask.copy()\n",
    "    aug_direction = original_direction.copy()\n",
    "    \n",
    "    # Apply different augmentation combinations\n",
    "    if aug_idx == 0:\n",
    "        # Original (no augmentation)\n",
    "        pass\n",
    "    elif aug_idx == 1:\n",
    "        # Intensity only\n",
    "        aug_cube = apply_intensity_augmentation(aug_cube)\n",
    "    elif aug_idx == 2:\n",
    "        # Noise only\n",
    "        aug_cube = apply_noise_augmentation(aug_cube)\n",
    "    elif aug_idx == 3:\n",
    "        # Geometric + intensity + noise\n",
    "        aug_cube, aug_mask, aug_direction = apply_geometric_augmentation(aug_cube, aug_mask, aug_direction)\n",
    "        aug_cube = apply_intensity_augmentation(aug_cube)\n",
    "        aug_cube = apply_noise_augmentation(aug_cube)\n",
    "    \n",
    "    augmented_data.append((aug_cube, aug_mask, aug_direction))\n",
    "\n",
    "# Visualize augmentations\n",
    "fig, axes = plt.subplots(n_augmentations, 4, figsize=(20, n_augmentations*4))\n",
    "aug_names = ['Original', 'Intensity Aug', 'Noise Aug', 'Combined Aug']\n",
    "\n",
    "for aug_idx in range(n_augmentations):\n",
    "    cube, mask, direction_map = augmented_data[aug_idx]\n",
    "    mid_z = cube.shape[0] // 2\n",
    "    \n",
    "    # Raw volume\n",
    "    im1 = axes[aug_idx, 0].imshow(cube[mid_z, :, :], cmap='gray', vmin=-2, vmax=2)\n",
    "    axes[aug_idx, 0].set_title(f'{aug_names[aug_idx]}: Raw Volume')\n",
    "    axes[aug_idx, 0].set_ylabel('Y (voxels)')\n",
    "    \n",
    "    # Volume with mask overlay\n",
    "    axes[aug_idx, 1].imshow(cube[mid_z, :, :], cmap='gray', alpha=0.7, vmin=-2, vmax=2)\n",
    "    mask_slice = mask[mid_z, :, :]\n",
    "    axes[aug_idx, 1].contour(mask_slice, levels=[0.5], colors='red', linewidths=2)\n",
    "    axes[aug_idx, 1].set_title('Volume + Mask')\n",
    "    \n",
    "    # Direction magnitude\n",
    "    direction_magnitude = np.linalg.norm(direction_map, axis=0)\n",
    "    im3 = axes[aug_idx, 2].imshow(direction_magnitude[mid_z, :, :], cmap='viridis')\n",
    "    axes[aug_idx, 2].set_title('Direction Magnitude')\n",
    "    \n",
    "    # Intensity histogram\n",
    "    axes[aug_idx, 3].hist(cube.flatten(), bins=50, alpha=0.7, density=True)\n",
    "    axes[aug_idx, 3].set_xlabel('Intensity')\\n    axes[aug_idx, 3].set_ylabel('Density')\n",
    "    axes[aug_idx, 3].set_title('Intensity Distribution')\n",
    "    axes[aug_idx, 3].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Add statistics text\n",
    "    stats_text = f'Mean: {cube.mean():.2f}\\\\nStd: {cube.std():.2f}\\\\nRange: [{cube.min():.2f}, {cube.max():.2f}]'\n",
    "    axes[aug_idx, 3].text(0.05, 0.95, stats_text, transform=axes[aug_idx, 3].transAxes, \n",
    "                         verticalalignment='top', bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))\n",
    "\n",
    "# Add x-labels to bottom row\n",
    "for col in range(4):\n",
    "    axes[-1, col].set_xlabel('X (voxels)' if col < 3 else 'Intensity')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Quantify augmentation effects\n",
    "print(\"üìä Augmentation Effects Summary:\")\n",
    "for aug_idx, (cube, mask, direction_map) in enumerate(augmented_data):\n",
    "    print(f\"   {aug_names[aug_idx]}:\")\n",
    "    print(f\"     Volume: mean={cube.mean():.3f}, std={cube.std():.3f}\")\n",
    "    print(f\"     Mask sum: {mask.sum():.0f} voxels\")\n",
    "    print(f\"     Direction active: {(np.linalg.norm(direction_map, axis=0) > 0).sum():,} voxels\")\n",
    "\n",
    "print(\"\\\\n‚úÖ Data augmentations demonstrated\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcd4fdbe",
   "metadata": {},
   "source": [
    "## Step 7: Final Training Batch Visualization\n",
    "\n",
    "Now let's see what the final training batch looks like after all preprocessing steps. This demonstrates:\n",
    "- **Batch structure**: How data is organized for PyTorch training\n",
    "- **Tensor shapes**: Input and target dimensions\n",
    "- **Data ranges**: Normalized values ready for neural network\n",
    "- **Quality checks**: Ensuring data integrity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bac66760",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create final training batch\n",
    "def create_training_batch(augmented_data, batch_size=None):\n",
    "    \"\"\"Create a training batch from augmented data\"\"\"\n",
    "    if batch_size is None:\n",
    "        batch_size = len(augmented_data)\n",
    "    \n",
    "    # Initialize batch tensors\n",
    "    batch_raw = []\n",
    "    batch_mask = []\n",
    "    batch_direction = []\n",
    "    \n",
    "    for i in range(min(batch_size, len(augmented_data))):\n",
    "        cube, mask, direction_map = augmented_data[i]\n",
    "        \n",
    "        # Add channel dimension and normalize\n",
    "        raw_normalized = (cube - cube.mean()) / (cube.std() + 1e-8)\n",
    "        raw_with_channel = raw_normalized[np.newaxis, ...]  # Add channel dim\n",
    "        \n",
    "        # Prepare mask (add channel dim)\n",
    "        mask_with_channel = mask[np.newaxis, ...]\n",
    "        \n",
    "        # Direction map is already (3, z, y, x)\n",
    "        \n",
    "        batch_raw.append(raw_with_channel)\n",
    "        batch_mask.append(mask_with_channel)\n",
    "        batch_direction.append(direction_map)\n",
    "    \n",
    "    # Stack into batch tensors\n",
    "    batch_raw = np.stack(batch_raw, axis=0)  # (B, 1, Z, Y, X)\n",
    "    batch_mask = np.stack(batch_mask, axis=0)  # (B, 1, Z, Y, X)\n",
    "    batch_direction = np.stack(batch_direction, axis=0)  # (B, 3, Z, Y, X)\n",
    "    \n",
    "    return batch_raw, batch_mask, batch_direction\n",
    "\n",
    "# Create training batch\n",
    "batch_raw, batch_mask, batch_direction = create_training_batch(augmented_data)\n",
    "\n",
    "print(\"üöÄ Final Training Batch:\")\n",
    "print(f\"   Raw data: {batch_raw.shape} (B, C, Z, Y, X)\")\n",
    "print(f\"   Masks: {batch_mask.shape} (B, C, Z, Y, X)\")  \n",
    "print(f\"   Directions: {batch_direction.shape} (B, 3, Z, Y, X)\")\n",
    "print(f\"   Raw data range: [{batch_raw.min():.3f}, {batch_raw.max():.3f}]\")\n",
    "print(f\"   Mask range: [{batch_mask.min():.1f}, {batch_mask.max():.1f}]\")\n",
    "print(f\"   Direction range: [{batch_direction.min():.3f}, {batch_direction.max():.3f}]\")\n",
    "\n",
    "# Visualize final batch\n",
    "fig, axes = plt.subplots(3, batch_raw.shape[0], figsize=(4*batch_raw.shape[0], 12))\n",
    "if batch_raw.shape[0] == 1:\n",
    "    axes = axes.reshape(-1, 1)\n",
    "\n",
    "for b in range(batch_raw.shape[0]):\n",
    "    mid_z = batch_raw.shape[2] // 2\n",
    "    \n",
    "    # Raw data\n",
    "    im1 = axes[0, b].imshow(batch_raw[b, 0, mid_z, :, :], cmap='gray')\n",
    "    axes[0, b].set_title(f'Batch {b}: Raw Input')\n",
    "    axes[0, b].set_xlabel('X')\n",
    "    axes[0, b].set_ylabel('Y')\n",
    "    plt.colorbar(im1, ax=axes[0, b], fraction=0.046)\n",
    "    \n",
    "    # Mask target\n",
    "    im2 = axes[1, b].imshow(batch_mask[b, 0, mid_z, :, :], cmap='Reds', vmin=0, vmax=1)\n",
    "    axes[1, b].set_title(f'Mask Target')\n",
    "    axes[1, b].set_xlabel('X')\n",
    "    axes[1, b].set_ylabel('Y')\n",
    "    plt.colorbar(im2, ax=axes[1, b], fraction=0.046)\n",
    "    \n",
    "    # Direction magnitude target\n",
    "    direction_mag = np.linalg.norm(batch_direction[b], axis=0)\n",
    "    im3 = axes[2, b].imshow(direction_mag[mid_z, :, :], cmap='viridis')\n",
    "    axes[2, b].set_title(f'Direction Target')\n",
    "    axes[2, b].set_xlabel('X')\n",
    "    axes[2, b].set_ylabel('Y')\n",
    "    plt.colorbar(im3, ax=axes[2, b], fraction=0.046)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Data quality checks\n",
    "print(\"\\\\nüîç Data Quality Checks:\")\n",
    "\n",
    "# Check for NaN or inf values\n",
    "has_nan_raw = np.isnan(batch_raw).any()\n",
    "has_inf_raw = np.isinf(batch_raw).any()\n",
    "has_nan_mask = np.isnan(batch_mask).any()\n",
    "has_nan_direction = np.isnan(batch_direction).any()\n",
    "\n",
    "print(f\"   Raw data: NaN={has_nan_raw}, Inf={has_inf_raw}\")\n",
    "print(f\"   Masks: NaN={has_nan_mask}\")\n",
    "print(f\"   Directions: NaN={has_nan_direction}\")\n",
    "\n",
    "# Check value ranges\n",
    "print(f\"   Raw normalization: mean={batch_raw.mean():.3f}, std={batch_raw.std():.3f}\")\n",
    "print(f\"   Mask values: unique={np.unique(batch_mask)}\")\n",
    "\n",
    "# Check spatial consistency\n",
    "for b in range(batch_raw.shape[0]):\n",
    "    mask_volume = batch_mask[b, 0].sum()\n",
    "    direction_active = (np.linalg.norm(batch_direction[b], axis=0) > 0).sum()\n",
    "    print(f\"   Batch {b}: mask_volume={mask_volume:.0f}, direction_active={direction_active}\")\n",
    "\n",
    "print(\"\\\\n‚úÖ Training batch ready for neural network!\")\n",
    "\n",
    "# Memory usage estimation\n",
    "raw_memory_mb = batch_raw.nbytes / (1024**2)\n",
    "mask_memory_mb = batch_mask.nbytes / (1024**2)\n",
    "direction_memory_mb = batch_direction.nbytes / (1024**2)\n",
    "total_memory_mb = raw_memory_mb + mask_memory_mb + direction_memory_mb\n",
    "\n",
    "print(f\"\\\\nüíæ Memory Usage:\")\n",
    "print(f\"   Raw data: {raw_memory_mb:.1f} MB\")\n",
    "print(f\"   Masks: {mask_memory_mb:.1f} MB\")\n",
    "print(f\"   Directions: {direction_memory_mb:.1f} MB\")\n",
    "print(f\"   Total per batch: {total_memory_mb:.1f} MB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10a71662",
   "metadata": {},
   "source": [
    "## Summary: Complete Training Pipeline Visualization\n",
    "\n",
    "üéâ **Congratulations!** You've now seen every step of the Synful training data pipeline:\n",
    "\n",
    "### Pipeline Steps Completed:\n",
    "1. ‚úÖ **TSV Data Loading**: Parsed pre/post synapse coordinates\n",
    "2. ‚úÖ **Spatial Analysis**: Analyzed 3D synapse distributions\n",
    "3. ‚úÖ **Vector Features**: Calculated direction vectors and distances  \n",
    "4. ‚úÖ **Volume Simulation**: Demonstrated zarr cube extraction\n",
    "5. ‚úÖ **Mask Generation**: Created binary detection targets\n",
    "6. ‚úÖ **Direction Mapping**: Generated 3D direction vector targets\n",
    "7. ‚úÖ **Data Augmentation**: Applied geometric, intensity, and noise augmentations\n",
    "8. ‚úÖ **Final Batching**: Prepared training-ready tensors\n",
    "\n",
    "### Key Insights:\n",
    "- üìä **Data Structure**: TSV ‚Üí coordinates ‚Üí training cubes ‚Üí neural network tensors\n",
    "- üéØ **Multitask Learning**: Both synapse detection (masks) and direction prediction (vectors)\n",
    "- üîÑ **Augmentation**: Robust training through diverse data variations\n",
    "- üíæ **Memory Efficiency**: Optimized tensor shapes for GPU training\n",
    "- üîç **Quality Control**: Validation at each pipeline stage\n",
    "\n",
    "### Next Steps:\n",
    "- Use this pipeline with real zarr volumes and TSV/MongoDB synapse data\n",
    "- Adjust parameters (cube_size, blob_radius, augmentation strength) as needed\n",
    "- Monitor training performance and data quality\n",
    "- Scale to production with larger datasets\n",
    "\n",
    "This notebook provides the foundation for understanding and debugging the complete Synful training data flow!"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
