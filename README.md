# Synful PyTorch: Modern Synaptic Partner Detection

[![Python 3.10+](https://img.shields.io/badge/python-3.10+-blue.svg)](https://www.python.org/downloads/)
[![PyTorch](https://img.shields.io/badge/PyTorch-2.1+-orange.svg)](https://pytorch.org/)
[![Lightning](https://img.shields.io/badge/Lightning-2.1+-purple.svg)](https://lightning.ai/)
[![CUDA](https://img.shields.io/badge/CUDA-12.1+-green.svg)](https://developer.nvidia.com/cuda-downloads)

**A complete modernization of the Synful framework for synaptic partner detection in 3D electron microscopy volumes.**

## ğŸš€ Overview

Synful PyTorch is a state-of-the-art deep learning framework for detecting synaptic partners in large-scale 3D electron microscopy datasets. This is a complete rewrite of the original Synful project, modernized with:

- **PyTorch 2.x** ecosystem with Lightning integration
- **Python 3.12** compatibility
- **CUDA 13** support for RTX 5090s and latest GPUs
- **Modern deep learning** practices and architectures
- **Production-ready** training and inference pipelines

> **Original Research**: This builds upon the groundbreaking work by Julia Buhmann and Jan Funke that achieved detection of 244 Million synaptic partners in the full adult fly brain (FAFB) dataset. See our [bioRxiv preprint](https://www.biorxiv.org/content/10.1101/2019.12.12.874172v1) for the original methodology.

## âœ¨ Key Features

### ğŸ§  Advanced Architecture
- **3D U-Net** with skip connections and modern components
- **Multi-task learning** for mask and direction vector prediction
- **Focal Loss** for handling class imbalance
- **Mixed precision** training for efficiency

### ğŸ”„ Modern Data Pipeline
- **Pydantic data structures** with validation
- **Chunked processing** for memory efficiency
- **Data augmentations** for robust training
- **Multiple data formats** (HDF5, Zarr, CloudVolume)

### âš¡ Training System
- **PyTorch Lightning** for scalable training
- **Automatic optimization** and scheduling
- **Model checkpointing** and experiment tracking
- **Multi-GPU support** with DDP

### ğŸ”® Inference Engine
- **Overlap-and-blend** for seamless predictions
- **GPU acceleration** with CPU fallback
- **Synapse detection** and post-processing
- **Configurable chunk sizes** for different hardware

## ğŸ› ï¸ Installation

### Requirements
- Python 3.10+
- PyTorch 2.1+
- CUDA 12.1+ (optional, for GPU acceleration)

### Quick Install
```bash
# Clone the repository
git clone https://github.com/yourusername/synful_cuda12x.git
cd synful_cuda12x

# Install in development mode
pip install -e .

# Install optional dependencies
pip install -e ".[vis,dev]"
```

### For Training/Inference
```bash
# Install full dependencies
pip install -e ".[vis]"
pip install lightning scikit-image
```

## ğŸš€ Quick Start

### Test Installation
```python
# Quick functionality test
python simple_test_synful.py

# Comprehensive test with visualizations
python test_synful_complete.py --output-dir ./results
```

### Basic Usage
```python
from synful import UNet3D, SynfulPredictor, Synapse, SynapseCollection

# Create and configure model
model = UNet3D(
    n_channels=1,
    base_features=16,
    depth=4,
    multitask=True
)

# Run inference on a volume
predictor = SynfulPredictor(
    model=model,
    chunk_size=(64, 512, 512),
    overlap=(8, 64, 64)
)

predictions = predictor.predict_volume(your_volume)
detected_synapses = predictor.detect_synapses(
    predictions['mask'],
    threshold=0.5
)
```

### Training Example
```python
from synful import SynfulTrainer, create_default_configs

# Create configurations
model_config, data_config, training_config = create_default_configs()

# Initialize trainer
trainer = SynfulTrainer(
    model_config=model_config,
    data_config=data_config,
    training_config=training_config,
    output_dir="./experiments",
    experiment_name="synapse_detection"
)

# Train model
trainer.train(
    train_dataloader=train_loader,
    val_dataloader=val_loader,
    max_epochs=100
)
```

## ğŸ“Š Model Architecture

The framework uses a modern 3D U-Net architecture optimized for synaptic partner detection:

```
Input (1, D, H, W)
â”œâ”€â”€ Encoder (ConvBlocks + Downsampling)
â”œâ”€â”€ Bottleneck (Dense features)
â”œâ”€â”€ Decoder (UpBlocks + Skip connections)
â””â”€â”€ Multi-task Output
    â”œâ”€â”€ Mask prediction (1, D, H, W)
    â””â”€â”€ Direction vectors (3, D, H, W)
```

Key components:
- **DoubleConv3D**: Two 3D convolutions with BatchNorm and activation
- **Down3D**: Downsampling with max pooling or strided convolution  
- **Up3D**: Upsampling with transposed convolution + skip connections
- **Skip connections**: Preserve fine-grained features for precise localization

The pipeline processes 3D raw data in two steps:
1. **Inference**: Predicts (a) `syn_indicator_mask` (postsynaptic locations) and (b) `direction_vectors` (pointing from postsynaptic to presynaptic partners)
2. **Synapse extraction**: (a) Location extraction based on `syn_indicator_mask` and (b) Finding presynaptic partners using `direction_vectors`

![method_figure](docs/_static/method_overview.png)


## ğŸ¯ Performance

### Test Results âœ…
All components have been tested and are working correctly:
- **Data Structures**: Pydantic validation working
- **Model Forward Pass**: Multi-task output successful
- **Training Components**: Lightning + Focal Loss functional
- **Inference Pipeline**: Chunked prediction working
- **Synapse Detection**: Post-processing successful

### Hardware Support
- **RTX 5090**: Full CUDA 13 support
- **RTX 4090/4080**: CUDA 12.1+ support
- **Legacy GPUs**: CUDA 11+ support
- **CPU Fallback**: Works without GPU
- **Memory Efficient**: Chunked processing for large volumes

## ğŸ“ Project Structure

```
synful_cuda12x/
â”œâ”€â”€ src/synful/           # Main package
â”‚   â”œâ”€â”€ synapse.py        # Data structures
â”‚   â”œâ”€â”€ models.py         # PyTorch models
â”‚   â”œâ”€â”€ training.py       # Training pipeline
â”‚   â”œâ”€â”€ inference.py      # Inference engine
â”‚   â”œâ”€â”€ data/            # Data processing
â”‚   â””â”€â”€ visualization/   # Plotting tools
â”œâ”€â”€ tests/               # Test suite
â”œâ”€â”€ docs/               # Documentation
â”œâ”€â”€ scripts/            # Example scripts
â”œâ”€â”€ example_training.py # Training example
â”œâ”€â”€ simple_test_synful.py # Quick test
â””â”€â”€ test_synful_complete.py # Full test suite
```

## ğŸ§ª Testing

Run the test suite to verify installation:

```bash
# Simple functionality test
python simple_test_synful.py

# Full test with visualizations
python test_synful_complete.py

# Training example
python example_training.py --epochs 5 --cpu
```

## ğŸ”„ Migration from TensorFlow

This modernized version provides significant improvements:

### Advantages over Original TensorFlow 1.x:
- **Simpler Setup**: No complex TensorFlow sessions or feed dictionaries
- **Better Performance**: Mixed precision, efficient data loading, modern optimizations
- **Easier Training**: PyTorch Lightning handles distributed training, checkpointing
- **Production Ready**: Robust inference pipeline with memory-efficient chunking
- **Type Safety**: Pydantic validation ensures data integrity
- **Modern Python**: Python 3.12 compatibility with latest ecosystem

### API Comparison:
```python
# Old TensorFlow 1.x approach
# Complex setup with sessions, feeds, placeholders...

# New PyTorch approach - much simpler!
from synful import UNet3D, SynfulPredictor
model = UNet3D(multitask=True)
predictor = SynfulPredictor(model)
results = predictor.predict_volume(volume)
```

## ğŸ“š Legacy Information

### Original System Requirements
- **Hardware**: GPU with 12+ GB memory (originally tested on GeForce GTX TITAN X)
- **Software**: Originally tested on Ubuntu 16.04 with TensorFlow 1.14

### Pretrained Models
The original repository provided pretrained models with the following performance on CREMI dataset:

|Model|Specifications|F-score with seg|F-score without|
|---|---|---|---|
|p_setup52|big, curriculum, CE, ST|0.76|0.74|
|p_setup51|big, curriculum, CE, MT_2|0.76|0.73|
|p_setup54|small, curriculum, MSE, ST|0.76|0.7|
|p_setup45|small, standard, MSE, MT2|0.73|0.68|

*Note: The modernized PyTorch implementation maintains compatibility with these performance benchmarks while providing improved usability and efficiency.*

## ğŸ¤ Contributing

We welcome contributions! To contribute:
1. Fork the repository
2. Create a feature branch
3. Make your changes and add tests
4. Run the test suite: `python test_synful_complete.py`
5. Submit a pull request

## ğŸ“„ License

This project is licensed under the MIT License - see [LICENSE](LICENSE) file.

## ğŸ™ Acknowledgments

- **Original Authors**: Julia Buhmann and Jan Funke for the groundbreaking Synful methodology
- **PyTorch Lightning**: For the excellent training framework
- **PyTorch Community**: For the robust ecosystem
- **Original Research**: Buhmann, J., Sheridan, A., Malin-Mayor, C. et al. *bioRxiv* (2019)

## ğŸ“§ Contact

For questions and support:
- **Issues**: Use GitHub Issues for bug reports and feature requests
- **Discussions**: Use GitHub Discussions for questions
- **Original Authors**: [Julia Buhmann](mailto:buhmannj@janelia.hhmi.org) and [Jan Funke](mailto:funkej@janelia.hhmi.org)

---

**ğŸš€ Ready to detect synapses at scale with modern deep learning! ğŸš€**
